{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAQa-twjR6bV"
      },
      "source": [
        "# COMP47700 Speech and Audio PL1: Digital signal analysis with Python\n",
        "---\n",
        "\n",
        "## Learning outcomes\n",
        "This practical tutorial covers the following learning outcomes within the COMP47700 Speech and Audio module:\n",
        "* Analyse speech and audio signals and features (**LO1**)\n",
        "  * Setup a basic working environment for signal analysis in Python.\n",
        "  * Identify core libraries used for speech and signal analysis in Python.\n",
        "* Describe the signal characteristics of speech and audio signals using appropriate terminology (**LO3**)\n",
        "  * Use Python to create a mathematical representation of digital signals.\n",
        "* Apply signal processing algorithms to speech and audio signals (**LO5**)\n",
        "  * Read, manipulate and write wav audio files in Python.\n",
        "  * Create visual representations of audio files in Python.\n",
        "\n",
        "## Module topics\n",
        "This practical tutorial builds on the following core topics:\n",
        "* Introduction to speech and audio processing (Unit 1)\n",
        "* Basic audio processing (Unit 2)\n",
        "\n",
        "## Why is it important?\n",
        "* Working environment\n",
        "  * Python is a versatile and flexible programming language that allows for easy integration with other technologies and frameworks for machine learning (e.g., TensorFlow, PyTorch) and data analysis (e.g., Pandas).\n",
        "* Digital signal understanding\n",
        "  * Python provides a wide selection of libraries and powerful tools for signal analysis (e.g., NumPy, Matplotlib, Librosa). These tools allow reading, manipulating, and visualising sound signals, which is crucial for understanding the characteristics of sound signals.\n",
        "\n",
        "\n",
        "## Structure of this tutorial\n",
        "This practical tutorial contains different sections:\n",
        "* **Live coding:** Basic theory, demos and coding examples presented by the lecturer on site (unmarked)\n",
        "* **Student activity:** Familiarisation and coding exercises to be completed by the students and followed by a short discussion on site (unmarked). These activities introduce key concepts and skills necessary to complete the assignments.\n",
        "* **Assignment:** Three (3) take home problem/coding questions to be completed by the students and due in two (2) weeks from the day the practical tutorial is given."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCo3U7Q2FKVr"
      },
      "source": [
        "## Setup notes\n",
        "We will be using Google Colabs for our labs but if you wish to run speech and audio projects locally (not recommended) you will need to manage your own Python environment setup with a number of important packages.\n",
        "\n",
        "Some important libraries for signal analysis in Python are:\n",
        "\n",
        "* [numpy](https://numpy.org) is the fundamental package for scientific computing with Python. From a signal processing perspective it allow us to represent continuous signals as discrete digitally sampled time series.\n",
        "* [matplotlib](https://matplotlib.org) is a plotting and data visualisation library. Pyplot is a Matplotlib module that allows MATLAB-like interface to the matplotlib library funtions. Practically speaking, this means that you can build up a figure plot step by step, e.g. create a figure, add axes, add data to plot, customise the title and axes labels and change to look of the figure.\n",
        "* [librosa](librosa.github.io) is a Python package for music and audio processing. It allows handling audio files and provides tasks for spectral analysis, feature extraction, spectrogram visualization, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNphYm7sd1aJ"
      },
      "source": [
        "### Downloading and extracting lab zip file from Github\n",
        "We will download and extract the content from the lab zip file on the Github:\n",
        "1. Use wget command to download the zip file from Github.\n",
        "2. Using the `zipfile` library, extract the files to your Google Colab environment (`./PL1_files/`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZiWjMRo-D_Vu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-02-06 21:08:16--  https://github.com/COMP47700-Speech-and-Audio/PL1-Digital-signal-analysis-with-Python/raw/main/PL1_files.zip\n",
            "Resolving github.com (github.com)... 4.208.26.197\n",
            "Connecting to github.com (github.com)|4.208.26.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/COMP47700-Speech-and-Audio/PL1-Digital-signal-analysis-with-Python/main/PL1_files.zip [following]\n",
            "--2025-02-06 21:08:16--  https://raw.githubusercontent.com/COMP47700-Speech-and-Audio/PL1-Digital-signal-analysis-with-Python/main/PL1_files.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 636466 (622K) [application/zip]\n",
            "Saving to: ‘PL1_files.zip’\n",
            "\n",
            "PL1_files.zip       100%[===================>] 621.55K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-02-06 21:08:16 (9.81 MB/s) - ‘PL1_files.zip’ saved [636466/636466]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the zip file\n",
        "!wget https://github.com/COMP47700-Speech-and-Audio/PL1-Digital-signal-analysis-with-Python/raw/main/PL1_files.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ibD2CpvLEDkT"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zipname = 'PL1_files.zip'\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zipname, 'r') as zip_ref:\n",
        "    zip_ref.extractall()  # Extract all files to the current directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W_JLO09R6bY"
      },
      "source": [
        "### **Live coding:** Introducing libraries and plotting with matplotlib\n",
        "First we will get our environment working and familiarising ourselves with matrix and array processing in Python.\n",
        "1. Import the libraries (`matplotlib, numpy, librosa`) and setup the nootbook for [magic](https://colab.research.google.com/github/jdwittenauer/ipython-notebooks/blob/master/notebooks/language/IPythonMagic.ipynb) plots.\n",
        "\n",
        "2. Create and display an array `[1,0,-1]` of 32-bit floating point numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c8Kl_fVfR6bZ"
      },
      "outputs": [],
      "source": [
        "#Imports and Magic\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0C1ASG2SR6ba"
      },
      "outputs": [],
      "source": [
        "numbers = np.array([0, np.pi/2, np.pi, 3*np.pi/2, 2*np.pi])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEmByu-eR6ba"
      },
      "source": [
        "### **Live coding:** Creating a digital signal\n",
        "1. Create and display an array of the `sin` of those numbers (using `numpy`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Mdvm6ptfR6bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 0.0000000e+00  1.0000000e+00  1.2246468e-16 -1.0000000e+00\n",
            " -2.4492936e-16]\n"
          ]
        }
      ],
      "source": [
        "sine_values = np.sin(numbers)\n",
        "print(sine_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK7Z6LWeR6bb"
      },
      "source": [
        "### **Live coding:** Introducing numpy arrays and floating point representations\n",
        "1. Create and display a matrix (or 2-D array) of floating point numbers, `m1` for integers in the range 0 to 3 to -3.\n",
        "2. Create a new numpy array, `array2` of 32-bit floats using `m1` as the input.\n",
        "\n",
        "What shape (i.e. matrix size) is the object `array2`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cl9w1n53R6bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of array2: (2, 4)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Create a 2-D array `m1` with floating point numbers for integers in the range 0 to 3 to -3\n",
        "# Here, we are creating a 2x4 matrix (2 rows and 4 columns) with specific floating point values\n",
        "m1 = np.array([[0.0, 1.0, 2.0, 3.0], [-1.0, -2.0, -3.0, 0.0]])\n",
        "\n",
        "# Step 2: Create a new numpy array `array2` of 32-bit floats using `m1` as the input\n",
        "# We are converting the data type of the elements in `m1` to 32-bit floating point numbers (float32)\n",
        "array2 = np.array(m1, dtype=np.float32)\n",
        "\n",
        "# Step 3: Display the shape of `array2`\n",
        "# The shape attribute of a numpy array returns a tuple representing the dimensions of the array\n",
        "# In this case, it will return (2, 4) indicating 2 rows and 4 columns\n",
        "print(\"Shape of array2:\", array2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc3c9jZ-R6bc"
      },
      "source": [
        "### **Live coding:** Ploting and manipulating numpy arrays\n",
        "1. Create and display a matrix (or 2-D array) of floating point numbers.\n",
        "2. Plot them using `matplotlib`.\n",
        "3. Find the `max_y` value and its index in the array (using `argmax`).\n",
        "4. Set it to zero and replot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG4m-FimR6bd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3Eqfi0LR6bd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHgXLFVGvRxF"
      },
      "source": [
        "### **Live coding:** Representing a signal digitally\n",
        "1. Create a sin wave with a period of 0.5 seconds (i.e. frequency = 2 Hz by the relationship $f=\\frac{1}{t}$)\n",
        "2. Sample the sin wave at 100 samples per second so the sampling frequency $f_s= 100$ Hz.\n",
        "3. Create an array of 201 sinusoidal signal wave samples\n",
        "4. Set up an array of time samples using `arange`.\n",
        "5. Compute the amplitude value $x$ of our wave at each time point $x=sin(2\\pi f t)$\n",
        "6. Plot the wave.\n",
        "\n",
        "**Notes:** `arange` is a NumPy library method. see [documentation](http://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html) for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDs6uD9ovN1c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb1DL7V1NCbl"
      },
      "source": [
        "### **Student activity #1:** Signal representation\n",
        "Generate and plot a sinusoidal signal using the following parameters:\n",
        "* `frequency = 10` (in Hz)\n",
        "* `duration = 2` (in seconds)\n",
        "* `sample_rate = 1000` (samples per second)\n",
        "\n",
        "**Note**: Syntax can sometimes be confusing: sampling frequency $f_s$ or sampling rate, sr, are different syntax for the same thing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OC4esJz8T7jp"
      },
      "outputs": [],
      "source": [
        "###############################\n",
        "## Student activity solution #1\n",
        "###############################\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2yCzhGXR6bd"
      },
      "source": [
        "### **Live coding:** Manipulating signal representations\n",
        "Slicing is how you get a part of an array or matrix in Python (read up the Python docs or a [tutorial](https://www.oreilly.com/learning/how-do-i-use-the-slice-notation-in-python) if you need reminding about Python slicing).\n",
        "1. Slice `x` from 0 to 1 seconds.\n",
        "2. Plot the sliced wave."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5536lzFtR6be"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC5pPZcJR6be"
      },
      "source": [
        "### **Live coding:** Reading and playing sounds (IPython widgets)\n",
        "Playing a sound from a wav file using `IPython` widgets in a Jupyter notebook.\n",
        "1. Import the libraries for audio retrival and playback.\n",
        "2. Use the audio file provided in the lab files.\n",
        "3. Instantiate a playback widget for playing the audio file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgsFXlahR6be"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd0xRrN2R6be"
      },
      "source": [
        "### **Live coding:** Reading and ploting wav signals (low level method)\n",
        "There are lots of ways of doing things in Python. We can do things at a low level, for example, reading a sound file and plotting the digital signal using the `wave` [library](https://docs.python.org/3.7/library/wave.html#module-wave)\n",
        "1. Import libraries\n",
        "2. Open file and read frames\n",
        "3. Plot sound file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF_DidgyR6bf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPJBc7_xR6bf"
      },
      "source": [
        "But if we want to have time on the x-axis rather than samples, we need to compute the time that corresponds to each sample.\n",
        "4. Compute time (`ts`) using sampling rate.\n",
        "5. Replot signal with the corresponding time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdDYkmtKR6bf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utbb8S07R6bf"
      },
      "source": [
        "### **Live coding:** Reading and ploting wav signals (using librosa)\n",
        "Reading and plotting wav files can also be done using `librosa`.\n",
        "1. Load wav file (`librosa.load`).\n",
        "2. Plot sound representation (`librosa.display.wavshow`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg0RpmW8R6bg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f6-23nBR6bg"
      },
      "source": [
        "### **Live coding:** Ploting waveforms and spectrograms\n",
        "Plot a monophonic waveform and a spectrogram time frequency representation for the human and synthetic welcome messages.\n",
        "1. Load the natural and synthetic wav files (using `librosa`).\n",
        "2. Plot waveform signals.\n",
        "3. Compute the audio signal representation in the frequency domain.\n",
        "  - Compute the Short-Time Fourier Transform (`librosa.stft`)\n",
        "  - Obtain the magnitude (amplitude) information (`np.abs`)\n",
        "  - Convert the amplitudes to a logarithmic scale (`librosa.amplitude_to_db`)\n",
        "4. Plot spectrogram representation (`librosa.display.specshow`).\n",
        "5. Instantiate playback widgets for playing the audio files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sN5Vcw2FR6bg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VOBXhBROMZ5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiUY1vJAOQrt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBFRjqmcvwK_"
      },
      "source": [
        "### **Live coding:** Normalising audio signals\n",
        "Normalizing the amplitude of a signal is to change the amplitude to meet a particular criterion. To do so, we use the the `librosa.util.normalize` function from `librosa`.\n",
        "1. Load wav files.\n",
        "2. Normalise the signal using `librosa.util.normalize`.\n",
        "3. Plot original and normalised wavforms versions of the wav file.\n",
        "4. Plot an attenuated version of the waveform with +/-0.3 headroom."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqoUKXsiKNI2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ki6Do1RcR6bh"
      },
      "source": [
        "Listen to the normalised original and the amplified clipped - can you hear the difference?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPvWRycdR6bh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtJeZDyge_FC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0v1zy9RfNIC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E73CIhRXKx_E"
      },
      "source": [
        "### **Student activity #2:** Signal normalisation\n",
        "* Generate an amplified version (amplified by 3) of the original signal (`snd`).\n",
        "* Limit the amplified version to a range of -1 to +1.\n",
        "* Plot the amplified version of the signal.\n",
        "* Instantiate a playback widget to play the amplified audio file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O76258LNL3Fp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GR1nEEvgfcXc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgVtCPoQfnI_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt7o3XRFR6bh"
      },
      "source": [
        "### **Live coding:** Quantization in Python\n",
        "An analogue sound is a continuous, infinitely divisable signal, represented as $s(t)$. A discrete time signal, has continuous amplitude resolution but it sampled at discrete times, represented as $s[t]$. Conversely a quantized analogue signal $x_Q(t)$ has discrete amplitute. A digital signal, is both time and amplitude discrete and is denoted with square brackets, $s_D[t]$.  A digitial signal has a sampling rate and a bit depth.\n",
        "1. Generate an discrete signal representation (`x`).\n",
        "2. Generate the quantized signal representation for the original signal (`xQ`).\n",
        "3. Calculate the quantization error `e` (difference between discrete and quantized).\n",
        "4. Plot the discrete signal, quantized signal, and error in the same figure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKm9K6fmR6bh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvKwglTRb4Nt"
      },
      "source": [
        "### **Student activity #3:** Signal quantization\n",
        "Use the provided signal (440 Hz, 8000 samples per second, 2 seconds duration) to:\n",
        "* Plot the original (discrete) signal.\n",
        "* Generate and plot the quantised version of that signal (quantization factor of 3).\n",
        "* Instantiate playback widgets for playing the audio files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHp-2AApTJkP"
      },
      "outputs": [],
      "source": [
        "###############################\n",
        "## Student activity solution #3\n",
        "###############################\n",
        "\n",
        "# Sample rate of the periodic signal we will generate\n",
        "Fs = 8000\n",
        "\n",
        "# Time duration of the signals\n",
        "t = np.linspace(0, 2, 2*Fs , False)  # 2s with 8000 samples/second=16k samples\n",
        "\n",
        "# Generate signal with 440 Hz frequency and quantize it\n",
        "sig1 = np.sin(2*np.pi*440*t)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xea6GUoBWXyD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkU3rCm8hAfm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNFg5dObciaw"
      },
      "source": [
        "### **Live coding:** Quantization in audio files\n",
        "1. Try the quantization effect over speech signals (`snd_norm`).\n",
        "2. Vary the quantization factors (16, 8, 3).\n",
        "3. Instantiate playback widgets for playing the audio files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAXj5HlFklfe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LFYxmxPuOUT"
      },
      "source": [
        "---\n",
        "# Assignment Questions PL1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od3hfFsfeNZv"
      },
      "source": [
        "### Download and extract the lab zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_Sg_yNceAtQ"
      },
      "outputs": [],
      "source": [
        "# Download the zip file\n",
        "!wget https://github.com/COMP47700-Speech-and-Audio/PL1-Digital-signal-analysis-with-Python/raw/main/PL1_files.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ScvX1VSeCLt"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zipname = 'PL1_files.zip'\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zipname, 'r') as zip_ref:\n",
        "    zip_ref.extractall()  # Extract all files to the current directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdDYwV2YFaY8"
      },
      "source": [
        "## Question 1\n",
        "**Discrete digital time series signal maninpuation.** Generate a periodic cosine/sine signal at 440 Hz with a dynamic range of `[-0.5 +0.5]` amplitute and 1 second duration. Fix the amplitude to zero for 200 samples (25ms @ sampling rate of 8000). This will give us a notch that we can hear in the pure tone. Plot the signal with labelled axes and title. Instantiate playback widgets for playing the audio. Use `numpy`, `matplotlib`, and `IPython.display` for this question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k88t2UXyjQ8G"
      },
      "outputs": [],
      "source": [
        "##################################\n",
        "## Assignment question solution #1\n",
        "##################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzrbTMwxjiGO"
      },
      "source": [
        "## Question 2\n",
        "**File handling, signal manipluation, domain transform and visualisations.**\n",
        "Read the given wave file containing the utterance 'I see nine apples'. Segment it to create a signal containing the word `apples`. Compute the STFT of the signal. Plot the time domain signal and spectrogram for the word `apples` with labelled axes for the subplots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykkxY_bygfZ5"
      },
      "outputs": [],
      "source": [
        "# Wav file for this question\n",
        "############################\n",
        "\n",
        "f_apples='./PL1_files/196959__margo-heston__i-see-nine-apples-m.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OT8pYBE0jpnl"
      },
      "outputs": [],
      "source": [
        "##################################\n",
        "## Assignment question solution #2\n",
        "##################################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFS9m_oFjuQr"
      },
      "source": [
        "## Question 3\n",
        "Read the wav file provided in this exercise. Slice the file to 0 to 2 s, name this signal `slice_signal`.  Amplify the `slice_signal` by 4 and name this signal `amplified_signal`. Take this resulting signal and normalise it to limit the amplitude range to -1 to +1, name this resulting signal `norm_signal`. Take `norm_signal` and apply a quantisation factor of 8, name this signal `q_signal`.\n",
        "\n",
        "Instantiate playback widgets for playing the audio for `slice_signal`, `amplified_signal`, and `q_signal`.\n",
        "\n",
        "In a single figure, plot the waveforms for `slice_signal`, `amplified_signal` and `q_signal`. Add a legend with labels for each waveform."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8W16-wDK8IuR"
      },
      "outputs": [],
      "source": [
        "# Wav file for this question\n",
        "############################\n",
        "\n",
        "h_comp='./PL1_files/hinesCOMP47700.wav'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
